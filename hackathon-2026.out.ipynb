{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LEAP Pangeo JupyterHub: Hackathon Data Access Guide\n",
        "\n",
        "**Urban Futures:** Co-Creating Climate Resilience in NYC  \n",
        "**Dates:** Thurs Jan 15- Sat Jan 17, 2026\n",
        "\n",
        "This notebook serves as a comprehensive guide for hackathon participants\n",
        "on: - Navigating the LEAP Pangeo JupyterHub environment - Finding and\n",
        "opening hackathon datasets hosted on **OSN pods (public, read-only)** -\n",
        "Using **rclone**, **xarray**, and **fsspec** to explore and load data\n",
        "efficiently - Writing intermediate and final results to **LEAP\n",
        "`leap-scratch` (temporary)** - Avoiding common pitfalls\n",
        "\n",
        "**Please refer to our technical documentation for more on LEAP Pangeo:**\n",
        "https://leap-stc.github.io/\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "## 1) Getting Started: Launching your JupyterHub\n",
        "\n",
        "When you sign into the LEAP Pangeo JupyterHub, you will start on a\n",
        "**Server Options** page before your environment launches. This is where\n",
        "you choose the compute profile (CPU/RAM/GPU) and the software image (the\n",
        "prebuilt environment).\n",
        "\n",
        "### Step-by-step: start your server\n",
        "\n",
        "1.  Log into the hub https://leap.2i2c.cloud/\n",
        "2.  If you are not already running a server, click **Start My Server**.\n",
        "3.  On the **Server Options** page, select:\n",
        "    -   **Image** (software environment)\n",
        "    -   **CPU/RAM profile** (how much compute you request)\n",
        "4.  Click **Start** and wait for your JupyterLab to open.\n",
        "\n",
        "### Choosing an image (software environment)\n",
        "\n",
        "-   **Recommended Default:** **1 CPU / 8 GB RAM**. This option is\n",
        "    sufficient for most hakcathon work.\n",
        "-   **GPU Option:** Select a GPU-enabled image *only if you are actively\n",
        "    running GPU-accelerated workloads (e.g., deep learning training)*\n",
        "\n",
        "### GPU only when necessary:\n",
        "\n",
        "-   GPUs are a shared resource.\n",
        "-   If many participants select the GPU profile simultaneously, the hub\n",
        "    can become unstable or fail to schedule servers.\n",
        "-   **Please use GPU only when actively running GPU tasks**, and switch\n",
        "    back to the default CPU profile when you’re done.\n",
        "\n",
        "### Best practices to avoid crashing shared resources\n",
        "\n",
        "-   Prefer the default profile unless you have a clear need.\n",
        "-   Do not “camp” on GPU resources while idle.\n",
        "-   Write outputs to `leap-scratch`, not your home directory.\n",
        "\n",
        "If you hit startup errors or long waits, switch back to the default\n",
        "profile first and retry.\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "## 2) Mental Model: how storage fits together\n",
        "\n",
        "You will interact with **three** main storage locations:\n",
        "\n",
        "### 2A) OSN Pod (S3-compatible object storage) - **public, read-only**\n",
        "\n",
        "-   These are the hackathon’s **published** datasets, so they remain\n",
        "    accessible to the public even after the event.\n",
        "-   You cannot write to the OSN pod\n",
        "-   You should only **read** directly from the OSN whenever possible (do\n",
        "    not download full datasets locally).\n",
        "\n",
        "### 2B) LEAP JupyterHub Home Directory (`/home/jovyan`) - **small, persistent**\n",
        "\n",
        "-   This is where your notebooks live.\n",
        "-   Storage is limited to 100 GB and shared infrastructure depends on\n",
        "    it.\n",
        "-   **HARD RULE:** do **not** store large datasets here. If your home\n",
        "    directory grows very large (over 100GB), it can cause the servers to\n",
        "    crash for everyone\n",
        "\n",
        "### 2C) LEAP `leap-scratch` (Google Cloud Storage bucket) - **writable, 30 days**\n",
        "\n",
        "-   This is where you should write:\n",
        "    -   intermediate files (data subsets, temporary exports)\n",
        "    -   model outputs and figures\n",
        "    -   anything else that is large GB\n",
        "-   `leap-scratch` is cleared after 30 days, so it is not intended for\n",
        "    long-term archiving\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "## 3) Why you need `leap-scratch`\n",
        "\n",
        "Even if the “source of truth” datasets are on OSN, you still need a\n",
        "writable workspace for: - **Subsetting:** You might extract NYC-only\n",
        "slices, specific time windows, or a few variables. - **Derived\n",
        "products:** Regrids, indices, summary tables, GeoJSON outputs, tiles,\n",
        "plots, ML features, etc. - **Team collaboration:** A shared scratch\n",
        "prefix is a convenient handoff point. - **Performance:** Writing\n",
        "computed intermediates (small) can accelerate iterative workflows\n",
        "without redoing expensive steps.\n",
        "\n",
        "**Key practice:** *Read big data from OSN; write small/medium artifacts\n",
        "to `leap-scratch`; keep home directory minimal.*\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "## 4) Using Git to collaborate with members\n",
        "\n",
        "During the hackathon, teams may choose to use **Git/GitHub** to\n",
        "collaborate on code, notebooks, and documentation.\n",
        "\n",
        "> A full Git + GitHub tutorial for JupyterHub is available here:\n",
        "> https://github.com/leap-stc/LEAPCourse-Climate-Pred-Challenges/blob/main/Tutorials/Github-Tutorial.md\n",
        "\n",
        "### How Git fits into JupyterHub\n",
        "\n",
        "On LEAP JupyterHub, Git is typically used to: - Share notebooks and\n",
        "scripts within a team - Track changes to analysis code - Collaborate\n",
        "asynchronously without emailing files\n",
        "\n",
        "## Two ways to use Git on JupyterHub\n",
        "\n",
        "### Option 1: Use the JupyterLab interface (recommended for beginners)\n",
        "\n",
        "JupyterLab includes a built-in **Git extension** that allows you to: -\n",
        "Clone repositories - View changed files - Commit and push changes - Pull\n",
        "updates from teammates\n",
        "\n",
        "You can access it from: - the **left sidebar** (Branch icon), or - the\n",
        "**Git** on the topbar menu\n",
        "\n",
        "### Option 2: Use the terminal (recommended if you know Git)\n",
        "\n",
        "You can also use Git from the Unix terminal inside JupyterHub.\n",
        "\n",
        "Example workflow: Open a terminal\n",
        "\n",
        "``` bash\n",
        "git clone https://github.com/<org-or-user>/<repo>.git\n",
        "cd <repo>\n",
        "git status\n",
        "git add .\n",
        "git commit -m \"Add analysis notebook\"\n",
        "git push\n",
        "```\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "## 5) Hackathon datasets (OSN layout and access)\n",
        "\n",
        "All hackathon datasets (HRRR, CorrDiff, and ERA5) are hosted on public\n",
        "OSN object storage. OSN uses an S3-compatible interface, which means you\n",
        "access data by combining: - an endpoint URL (where the storage service\n",
        "lives) - a bucket name (the top-level container) - a prefix (a “folder”\n",
        "path inside the bucket)\n",
        "\n",
        "For this hackathon, these values are:\n",
        "\n",
        "    OSN_ENDPOINT_URL = \"https://nyu1.osn.mghpcc.org\"\n",
        "    OSN_BUCKET = \"leap-pangeo-manual\"\n",
        "    HACKATHON_PREFIX = \"hackathon-2026/\"\n",
        "\n",
        "**All datasets live under the following path:**\n",
        "\n",
        "    OSN_ROOT = f\"s3://{OSN_BUCKET}/{HACKATHON_PREFIX}\" \n",
        "\n",
        "    # For this hackathon: s3://leap-pangeo-manual/hackathon-2026/\n",
        "\n",
        "Inside this root directory, you will find separate subdirectories for\n",
        "each dataset: - `hrrr/` – High-Resolution Rapid Refresh weather model\n",
        "output - `era5_cds/NYC/` – ERA5 reanalysis data clipped to the NYC\n",
        "region - `corrdiff/` – CorrDiff downscaled model outputs\n",
        "\n",
        "**Note:** When working in Python, you do not include the endpoint URL in\n",
        "the s3:// path. Instead, you provide the endpoint separately and\n",
        "reference data using the bucket and prefix, as shown in later examples.\n",
        "\n",
        "This separation (endpoint vs. bucket vs. prefix) is important and is a\n",
        "common source of confusion when working with S3-compatible storage.\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "## 6) Reading data directly from OSN with Python (xarray + fsspec)\n",
        "\n",
        "The goal is to avoid downloading full datasets. Instead, open them in\n",
        "*in place* using `xarray` + `fsspec` (via `s3fs`)\n",
        "\n",
        "### Install/import the usual stack\n",
        "\n",
        "    import os\n",
        "    import xarray as xr\n",
        "    import s3fs\n",
        "    import fsspec\n",
        "\n",
        "### 6A) Create an anonymous S3 filesystem for OSN / List Directories\n",
        "\n",
        "    # Anonymous access to a public OSN endpoint\n",
        "    fs_osn = s3fs.S3FileSystem(\n",
        "        anon=True,\n",
        "        client_kwargs={\"endpoint_url\": OSN_ENDPOINT_URL},\n",
        "    )\n",
        "\n",
        "    # Test: list top-level within the hackathon prefix\n",
        "    fs_osn.ls(f\"{OSN_BUCKET}/{HACKATHON_PREFIX}\")[:20]\n",
        "\n",
        "### 6B) Open Zarr datasets\n",
        "\n",
        "The `hrrr` and `era5_cds` datasets are stored in Zarr format. You can\n",
        "open Zarr datasets like this:\n",
        "\n",
        "    #Example: replace with a real Zarr path you discover via listing\n",
        "    example_zarr_path = f\"{OSN_BUCKET}/{HACKATHON_PREFIX}hrrr/<some-variable>/<some-store>.zarr\"\n",
        "\n",
        "    mapper = fs_osn.get_mapper(example_zarr_path)\n",
        "\n",
        "    # Open dataset\n",
        "    ds = xr.open_zarr(mapper, consolidated=False)  # consolidated=True if metadata consolidated\n",
        "\n",
        "    ds\n",
        "\n",
        "**Cautions (Zarr):** - Do **not** call `.load()` on the full dataset.\n",
        "\n",
        "For more information on Zarr files, please refer to\n",
        "https://docs.xarray.dev/en/stable/user-guide/dask.html\n",
        "\n",
        "### 6C) Open NetCDF / Other Formats\n",
        "\n",
        "If data is NetCDF (.nc), you can open via fsspec and xarray like this:.\n",
        "\n",
        "``` python\n",
        "import xarray as xr\n",
        "\n",
        "# Example NetCDF path\n",
        "example_nc = f\"s3://{OSN_BUCKET}/{HACKATHON_PREFIX}corrdiff/<somefile>.nc\"\n",
        "\n",
        "ds_nc = xr.open_dataset(\n",
        "    example_nc,\n",
        "    engine=\"h5netcdf\",\n",
        "    storage_options={\n",
        "        \"anon\": True,\n",
        "        \"client_kwargs\": {\"endpoint_url\": OSN_ENDPOINT_URL},\n",
        "    },\n",
        ")\n",
        "\n",
        "ds_nc\n",
        "```\n",
        "\n",
        "**Cautions (NetCDF):** - Avoid opening dozens/hundreds of remote `.nc`\n",
        "files at once. - If you need many files, work in batches and aggregate\n",
        "outputs (e.g., per-day/per-month metrics), not full raw arrays. - If you\n",
        "hit performance issues, stage the needed files to `leap-scratch` and\n",
        "work from there.\n",
        "\n",
        "For more information on how to navigate and subset NetCDF files, please\n",
        "refer to https://docs.xarray.dev/en/stable/user-guide/io.html#netcdf\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "## 7) Writing outputs to `leap-scratch` (GCS): the safe writable workspace\n",
        "\n",
        "There are two ways outputs can end up in `leap-scratch`: writing\n",
        "directly to `leap-scratch` and moving files from home directory to\n",
        "`leap-scratch`. The first method is strongly preferred.\n",
        "\n",
        "### 7A) Using `gcsfs` for scratch I/O\n",
        "\n",
        "    import gcsfs\n",
        "\n",
        "    # This will use your JupyterHub credentials (already set up on LEAP hub)\n",
        "    fs_gcs = gcsfs.GCSFileSystem()\n",
        "\n",
        "    # Fill in a scratch prefix given to you or choose a team folder\n",
        "    # Example structure: gs://leap-scratch/hackathon-2026/<team-name>/\n",
        "    SCRATCH_PREFIX = \"leap-scratch/hackathon-2026/\"\n",
        "\n",
        "    # List (should work if you have access)\n",
        "    fs_gcs.ls(SCRATCH_PREFIX)[:20]\n",
        "\n",
        "### 7B) First Method: Write outputs directly to `leap-scratch`\n",
        "\n",
        "Most outputs (tables, model results, derived datasets) are created **in\n",
        "memory** as Python objects.  \n",
        "The safest and most efficient approach is to **write them directly to\n",
        "`leap-scratch`** without saving them locally.\n",
        "\n",
        "Example: write a Pandas DataFrame to `leap-scratch`\n",
        "\n",
        "``` python\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import gcsfs\n",
        "\n",
        "fs_gcs = gcsfs.GCSFileSystem()\n",
        "\n",
        "SCRATCH_PREFIX = \"leap-scratch/hackathon-2026/<team-name>/\"\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"timestamp\": [datetime.utcnow().isoformat()],\n",
        "    \"note\": [\"example output\"]\n",
        "})\n",
        "\n",
        "out_csv = f\"{SCRATCH_PREFIX}outputs/example.csv\"\n",
        "\n",
        "with fs_gcs.open(out_csv, \"w\") as f:\n",
        "    df.to_csv(f, index=False)\n",
        "\n",
        "out_csv\n",
        "```\n",
        "\n",
        "### 7C) Second Method: Move or copy files from home directory to `leap-scratch`\n",
        "\n",
        "Sometimes a file already exists locally (ex: a plot image or a file\n",
        "created by a tool that writes to disk).  \n",
        "In that case, you can **copy** the file from your home directory into\n",
        "`leap-scratch`.\n",
        "\n",
        "Example: copy a local image file to `leap-scratch`\n",
        "\n",
        "``` python\n",
        "import gcsfs\n",
        "\n",
        "fs_gcs = gcsfs.GCSFileSystem()\n",
        "\n",
        "local_file = \"/home/jovyan/output.png\"\n",
        "scratch_file = \"leap-scratch/hackathon-2026/<team-name>/outputs/output.png\"\n",
        "\n",
        "fs_gcs.put(local_file, scratch_file)\n",
        "\n",
        "scratch_file\n",
        "```\n",
        "\n",
        "*Note: This should not be your default workflow to avoid large files in\n",
        "your JupyterHub home directory*\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "## 8) Opening files from `leap-scratch` (GCS)\n",
        "\n",
        "### 8A) CSV → Pandas\n",
        "\n",
        "``` python\n",
        "import pandas as pd\n",
        "\n",
        "csv_path = \"gs://leap-scratch/hackathon-2026/<team-name>/outputs/table.csv\"\n",
        "\n",
        "with fs_gcs.open(csv_path, \"r\") as f:\n",
        "    df = pd.read_csv(f)\n",
        "\n",
        "df.head()\n",
        "```\n",
        "\n",
        "### 8B) Parquet → Pandas\n",
        "\n",
        "``` python\n",
        "import pandas as pd\n",
        "\n",
        "pq_path = \"gs://leap-scratch/hackathon-2026/<team-name>/outputs/table.parquet\"\n",
        "with fs_gcs.open(pq_path, \"rb\") as f:\n",
        "    df = pd.read_parquet(f)\n",
        "```\n",
        "\n",
        "### 8C) JSON → Python\n",
        "\n",
        "``` python\n",
        "import json\n",
        "\n",
        "json_path = \"gs://leap-scratch/hackathon-2026/<team-name>/outputs/config.json\"\n",
        "with fs_gcs.open(json_path, \"r\") as f:\n",
        "    obj = json.load(f)\n",
        "obj\n",
        "```\n",
        "\n",
        "### 8D) NetCDF (`.nc`) → Xarray\n",
        "\n",
        "``` python\n",
        "import xarray as xr\n",
        "\n",
        "nc_path = \"gs://leap-scratch/hackathon-2026/<team-name>/derived/subset.nc\"\n",
        "with fs_gcs.open(nc_path, \"rb\") as f:\n",
        "    ds = xr.open_dataset(f)\n",
        "ds\n",
        "```\n",
        "\n",
        "### 8E) Zarr store → Xarray\n",
        "\n",
        "``` python\n",
        "import xarray as xr\n",
        "\n",
        "zarr_path = \"gs://leap-scratch/hackathon-2026/<team-name>/derived/subset.zarr\"\n",
        "ds = xr.open_zarr(fs_gcs.get_mapper(zarr_path))\n",
        "ds\n",
        "```\n",
        "\n",
        "**Caution (GCS):** Prefer Zarr for large multi-dimensional arrays.\n",
        "NetCDF is fine for smaller derived subsets.\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "## 9) A minimal “pattern” for hackathon work\n",
        "\n",
        "1.  **Explore**: list OSN prefixes; find the dataset you need  \n",
        "2.  **Open**: `xr.open_zarr(...)` from OSN (lazy)  \n",
        "3.  **Subset/derive**: compute only what you need for NYC + your time\n",
        "    window  \n",
        "4.  **Persist**: save reduced data or derived outputs to\n",
        "    `leap-scratch`  \n",
        "5.  **Visualize/ship**: build your demo/visualization using scratch\n",
        "    outputs\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "## 10) If something fails\n",
        "\n",
        "-   If listing OSN returns empty: verify endpoint URL, bucket, prefix\n",
        "-   If you see permissions errors on scratch: confirm your\n",
        "    `leap-scratch` path and access\n",
        "-   If xarray says “No group found in store”: you may be pointing at a\n",
        "    non-zarr path; list deeper and confirm `.zarr` store root\n",
        "-   If things are slow: reduce request size (fewer timesteps/variables),\n",
        "    use `chunks=` and avoid eager reads"
      ],
      "id": "13a0280b-79b2-4bab-a95d-02b51ce26d1f"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  }
}